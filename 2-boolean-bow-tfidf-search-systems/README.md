# Buscador Booleano/bag-of-words e buscador com TF-IDF // Boolean/bag-of-words search system and TF-IDF search system
By JÃºlia Ferreira Tessler

*I was out of office this week, attending [KHIPU](khipu.ai) and, because of that, I wasn't able to complete this project.*

Although the instructions to this project are in Portuguese, I chose to write it in English because ChatGPT usually works better for prompts in English.

## How to run this project?
The intention here is that everything you need is in the Google Colab notebook available in this repository. It is possible that, if you plan on running the notebook yourself, you'll need a Google Colab Pro account, to avoid errors due to lack of resources. Regardless, running this notebook is simple: just follow the steps on the cells.

The version uploaded to this repository keeps all of the notebook outputs run in that exact order. Due to Pyserini installation and configuration steps, the outputs can be quite verbose and lengthy, which might affect your experience when reading this code on GitHub.

## TREC-DL 2020 Dataset
_Text mostly generated by ChatGPT_

TREC-DL (Text Retrieval Conference - Deep Learning) is an annual event that focuses on developing and evaluating techniques for information retrieval using deep learning methods. The TREC-DL 2020 dataset is a benchmark dataset used in the competition of the same name, which was held in November 2020.

The dataset consists of a collection of documents and queries in English, along with relevance judgments for each query-document pair. The documents were sourced from a subset of the Common Crawl web corpus and were preprocessed to remove boilerplate content and non-English text. The queries were collected from the Bing query logs and were manually refined by human assessors to ensure quality.

The TREC-DL 2020 dataset contains over 8 million documents and 43,000 queries, with an average of 191 documents per query. The relevance judgments were provided by human assessors and are binary, indicating whether a given document is relevant or not relevant to a given query. The dataset is intended for use in training and evaluating neural information retrieval models, with the goal of achieving high accuracy in retrieving relevant documents.

Overall, the TREC-DL 2020 dataset is a valuable resource for researchers and practitioners in the field of information retrieval, providing a realistic and challenging testbed for developing and evaluating deep learning models for text-based search applications.

### Data preparation

Following the steps in the [handout Pyserini documentation](https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-passage.md), after environment setup and data download and extraction, it is needed to convert the collection into Pyserini's JSONL files (with one JSON object per line). This step generates 9 JSONL files, with 1M lines each (apart from the last one, which has 841,823 lines).

Next up, we're able to index these documents as a `JsonCollecion` using Pyserini, which results in an index with 8,841,823 documents. For this step, the extra computational resources provided by Google Colab Pro where very helpful.

Finally, we can use BM25 to perform searches. For that, we used `k1 = 1.20` and `b = 0.75` as suggested by [Practical BM25 - Part 3: Considerations for Picking b and k1 in Elasticsearch](https://www.elastic.co/blog/practical-bm25-part-3-considerations-for-picking-b-and-k1-in-elasticsearch). With that, we were able to achieve NDCG@10 = 0.4836.

